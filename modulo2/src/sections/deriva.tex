\section{Derivabilità e differenziabilità}

\subsection{Derivabilità di funzioni scalari}
In generale quando ci si trova in $\mathbb{R}^1$ si definisce la derivata di 
una funzione su un intervallo aperto del tipo $]a, b[$. Questo perché se si 
definisce la derivata su un intervallo chiuso si avrebbero dei problemi in 
quanto potrebbe esistere solo la derivata destra o sinistra in un punto. 
Definiamo quindi l'equivalente degli intervalli aperti in $\mathbb{R}^n$.
\dfn{
	Dato $A \subseteq \mathbb{R}^n$, dico che \textbf{$\mathbf{A}$ è aperto} 
    se: 
	\begin{equation*}
		\forall x_0 \in A, \exists \epsilon > 0: \mathcal{B}(x_0, \epsilon) 
		\subseteq A
	\end{equation*}
}
Se ci mettiamo in $\mathbb{R}^2$ un insieme di questo tipo è dato da un figura 
con i bordi tratteggiati, cioè dove tutti i punti sul bordo non appartengono 
all'insieme $A$. %(FARE FIGURA?)

\thm{
	\textbf{Individuazione degli intervalli aperti:} Data $f: \mathbb{R}^n \to 
	\mathbb{R}$ continua, $\forall b \in \mathbb{R}$ l'insieme $\{x \in 
	\mathbb{R}^n \;|\; f(x) > b\}$ è aperto. L'apertura è data dal fatto che 
	l'insieme è definito tramite ugualianza stretta.
}
\subsubsection{Derivate parziali di funzioni scalari}
\dfn{
	Dato $A \subseteq \mathbb{R}^2$ aperto e sia $(x_0, y_0) \in A$. Si dice 
    che $f$ \textbf{è derivabile rispetto a $\mathbf{x}$ in 
    $\mathbf{(x_0, y_0)}$} se esiste \textbf{finito}:
	\begin{equation*}
		\pdv{f}{x} (x_0, y_0) \vcentcolon = \lim_{t \to 0} = 
		\dfrac{f(x_0 + t, y_0) - f(x_0, y_0)}{t} \in \mathbb{R}
	\end{equation*}
	Questo limite si indica con il simbolo di derivata parziale ($\partial$). 
	Di seguito alcune notazioni equivalenti:
	\begin{equation*}
		\pdv{f}{x} = \partial_x f = D_x f
	\end{equation*}
	Equivalentemente possiamo riscrivere il limite come:
	\begin{equation*}
		\pdv{f}{x} (x_0, y_0) \vcentcolon = \lim_{x \to x_0} = 
		\dfrac{f(x, y_0) - f(x_0, y_0)}{x - x_0} \in \mathbb{R}
	\end{equation*}
}
Vale ovviamente che la derivata rispetto a $y$ in $(x_0, y_0)$ risulta:
\begin{equation*}
		\pdv{f}{y} (x_0, y_0) \vcentcolon = \lim_{t \to 0} = 
		\dfrac{f(x_0, y_0 + t) - f(x_0, y_0)}{t} \in \mathbb{R}
\end{equation*}
Opppure equivalentemente:
\begin{equation*}
	\pdv{f}{y} (x_0, y_0) \vcentcolon = \lim_{y \to y_0} = \dfrac{f(x_0, y) - 
	f(x_0, y_0)}{y - y_0} \in \mathbb{R}
\end{equation*}

Esempio: prendiamo la funzione $f(x, y) = xy^2$. Le sue derivate parziali sono:
\begin{equation*}
	\pdv{f}{x} (x, y) = y^2 \qquad \pdv{f}{y} (x, y) = 2xy
\end{equation*}
L'idea per calcolare queste derivate è quella di considerarle come una funzioni
normale (cioè come quelle viste in $\mathbb{R}^1$) e di considerare come 
variabile quella che bisogna derivare, mentre tutte le altre vengono 
considerate costanti. Nel primo caso infatti, dove abbiamo derivato rispetto 
alla $x$, ci è bastato considerare la $y$ costante. Quindi è come se avessimo 
fatto la derivata in $\mathbb{R}^1$ della semplice funzione:
\begin{equation*}
	f(x) = a^2 \cdot x \implies f'(x) = a^2
\end{equation*}
Dove però al posto della $a$ ci sarebbe la $y$. Nel secondo caso invece la 
derivata è rispetto alla $y$, quindi la $x$ viene considerata come semplice 
costante: $f(y) = a \cdot y^2 \implies f'(y) = 2ay$. Dove ovviamente al posto 
della $a$ ci sarebbe la $x$.\bigbreak

Se si vuole \textbf{generalizzare la definzione di derivata pariziale} è 
necessario riprendere la definzione di vettori coordinati (Sezione: 
\ref{sec_vettoriCoordinati}). In generale quindi data $f: \mathbb{R}^n \to 
\mathbb{R}$ e un punto $\overline{x} \in \mathbb{R}^n$ si definisce la 
\textit{i}-esima derivata parziale come:
\begin{equation*}
	\pdv{f}{x_i}(\overline{x}) = \lim_{t \to 0} \dfrac{f(\overline{x} + t 
	\cdot e_i) - f(\overline{x})}{t}
\end{equation*}

\subsubsection{Gradiente}
Le derivate parziali si possono aggregare in una funzione vettoriale (cioè che 
restituisce un vettore) chiamata gradiente:
\dfn{
	Data una funzione $f: A \in \mathbb{R}$ con $A \subseteq \mathbb{R}^n$, 
	se esistono tutte le derivate pariziali di $f$ in ogni punto possiamo 
	definire \textbf{il gradiente di $\mathbf{f}$} come:
	\begin{equation*}
		\nabla f(x_1, x_2, \cdots) = \left(\pdv{f}{x_1}(x_1, x_2, \cdots), 
		\pdv{f}{x_2} (x_1, x_2, \cdots), \cdots  \right)
	\end{equation*}
	Nel caso particolare di $\mathbb{R}^2$:
	\begin{equation*}
		\nabla f(x, y) = \left(\pdv{f}{x}(x, y), \pdv{f}{y}(x, y)\right)
	\end{equation*}
	Il simbolo del gradiente ($\nabla$ si lege \textit{nabla}).
}
Esempio: data la funzione $f(x, y) = \sin(x + y^2)$ il suo gradiente risulta:
\begin{equation*}
	\nabla f (x, y) = (\cos(x + y^2), \cos(x + y^2) \cdot 2y)
\end{equation*}

\subsubsection{Derivabilità e continuità di funzioni scalari}
In $\mathbb{R}^1$ vale la relazione:
\begin{equation*}
	f \text{ derivabile in } x \implies f \text{ continua in } x
\end{equation*}
Questa affermazione vale ache in generale? Cioè se per esempio prendiamo una 
funzione scalare con le derivate parziali definiti, allora questa funzione è 
continua? Proviamo a verificarlo\footnote{La seguente non è una dimostrazione 
di un teorema. Ho comunque voluto evidenziarla perché potrebbe risultare 
effettivamente importante}:
\pf{
	Vogliamo provare che presa una funzione scalare con dominio maggiore di 
	$\mathbb{R}$ se esitono tutte le sue derivate parziali in un punto non vuol 
	dire che quella funzione è derivabile. In particoalare data $f:\mathbb{R}^2 
	\to \mathbb{R}$:
	\begin{equation*}
		\exists \partial_x f(x, y), \partial_y f(x, y) \centernot \implies f 
		\text{ continua}
	\end{equation*}

	Per dimostrare che qualcosa non è vero basta portare un controesempio: 
	prendiamo la funzione definita:
	\begin{equation*}
		f(x, y) = 
		\begin{cases}
			\dfrac{xy}{x^2 + y^2} &\text{ se }(x, y) \neq (0, 0)\\
			0 &\text{ se }(x, y) = (0, 0)
		\end{cases}
	\end{equation*}
	Mostriamo quindi che esistono le derivate parziali in $(0, 0)$ ma la 
	funzione è discontinua in $(0, 0)$.
	\begin{align*}
		\partial_x f(0, 0) = \lim_{t \to 0} \dfrac{f(t, 0) - f(0)}{t} = 
		\lim_{t \to 0} \dfrac{\dfrac{t\cdot 0}{t^2 + 0} - 0}{t} = 
		\lim_{t \to 0} \dfrac{0 - 0}{t} = 0
	\end{align*}
	Da notare che questa non è una forma indeterminata perché dalla 
	definzione di limite $t \neq 0 \; \forall t \in \mathbb{R}$. Il 
	numeratore invece è esattamente $0$. Per la derivata parziale rispetto 
	a $y$ si fa esattamente la stessa cosa in quanto la funzione è 
	simmetrica. Le derivate parziali quindi esistono:
	\begin{align*}
		\partial_x f(0, 0) = 0\\
		\partial_y f(0, 0) = 0\\
	\end{align*}
	Mostriamo ora che non è continua: prendiamo due successioni che tendono 
	a $(0, 0)$:
	\begin{align*}
		(u_n, v_n) &= \left(0, \dfrac{1}{n}\right) \xrightarrow[n \to + 
		\infty]{} (0, 0)\\
		(x_n, y_n) &= \left(\dfrac{1}{n}, \dfrac{1}{n}\right) 
		\xrightarrow[n \to + \infty]{} (0, 0)
	\end{align*}
	Per essere continua devono valere i seguenti limiti:
	\begin{align*}
		f(u_n, v_n) \xrightarrow[n \to +\infty]{} f(0, 0) = 0\\
		f(x_n, y_n) \xrightarrow[n \to +\infty]{} f(0, 0) = 0
	\end{align*}
	Mostriamo che solo il primo vale:
	\begin{equation*}
		f(u_n, v_n) = \dfrac{0 \cdot \dfrac{1}{n}}{0^2 + \dfrac{1}{n^2}} 
		\xrightarrow[n \to +\infty]{} 0
	\end{equation*}
	\begin{equation*}
		f(x_n, y_n) = \dfrac{\dfrac{1}{n} \cdot \dfrac{1}{n}}
		{\dfrac{1}{n^2} + \dfrac{1}{n^2}} = \dfrac{\dfrac{1}{n^2}}
		{2 \cdot \dfrac{1}{n^2}} = \dfrac{1}{2} \; \forall n
	\end{equation*}
	Ne consegue che la funzione è discontinua.
	\hfill Qed.
}
Abbiamo visto che non vale la relazione:
\begin{equation*}
	f \text{ derivabile in } x \implies f \text{ continua in } x
\end{equation*}
Quella che però vale è:
\begin{equation*}
	f \text{ differenziabile in } x \implies f \text{ continua in } x
\end{equation*}

\subsection{Differenziabilità di funzioni scalari}
In $\mathbb{R}^1$ preso un punto $x_0 \in \mathbb{R}$ vale che:
\begin{equation*}
	\exists f'(x_0) \in \mathbb{R} \iff \lim_{h \to 0} \dfrac{f(x_0 + h) - 
	f(x_0)}{h} = f'(x_0)
\end{equation*}
Possiamo riscrivere il limite come segue (mantenendo sempre il \textit{se e 
solo se}):
\begin{align*}
	&\iff \lim_{h \to 0} \dfrac{f(x_0 + h) - f(x_0) - h \cdot f'(x_0)}{h} 
	= 0\\[5pt]
	&\iff f(x_0 + h) - f(x_0) - f'(x_0) \cdot h = o(h)\\[5pt]
	&\iff f(x_0 + h) = f(x_0) + f'(x_0) \cdot h + o(h)
\end{align*}
Questa è la formula di Taylor di ordine $1$ per $h \to 0$. Se facciamo una 
sostituzione del tipo $x_0 + h = x$ possiamo riscrivere la formula per 
$x \to x_0$:
\begin{equation*}
	f(x) = f(x_0) + f'(x_0) (x - x_0) + o(x - x_0)
\end{equation*}

\dfn{
	\textbf{Notazioni per o-piccoli}: Sia $f:\mathbb{R}^2 \to \mathbb{R}$ 
	si scrive che (con $p > 0$): 
	\begin{equation*}
		f(x, y) = o(\lVert (x, y) \rVert^p)
	\end{equation*}
	se: 
	\begin{equation*}
		\forall \epsilon > 0, \exists \delta > 0, \forall (x, y) : 
		\lVert (x, y) \rVert < \delta \implies |f(x, y)| \leq \epsilon 
		\cdot \lVert (x, y) \rVert^p
	\end{equation*}
	Se $(x, y) \neq (0, 0)$ si può riscrivere come:
	\begin{equation*}
		\cdots \implies \dfrac{f(x, y)}{\lVert (x, y) \rVert^p} \leq 
		\epsilon
	\end{equation*}
	Equivalentemente\footnote{In realtà non è perfettamente equivalente 
	perché il rapporto non sarebbe ben definito se $(x_n, y_n)$ assumesse 
	il valore $(0, 0)$. In generale è quindi preferibile la prima 
	definzione.}:
	\begin{equation*}
		\forall (x_n, y_n) \to (0, 0) \quad \text{ vale }\quad 
		\lim_{n \to +\infty} \dfrac{f(x_n, y_n)}{\lVert (x_n, y_n) 
		\rVert^p} = 0
	\end{equation*}
}
Esempio: verifichiamo che la funzione $f(x, y) = x^2$ è o-piccolo di $\lVert 
(x, y) \rVert$ per $(x, y) \to (0, 0)$. In questo caso $p = 1$. Deve quindi 
valere il limite:
\begin{equation*}
	\lim_{(x, y) \to (0, 0)} \dfrac{f(x, y)}{\lVert (x, y) \rVert^p} = 
	\lim_{(x, y) \to (0, 0)} \dfrac{x^2}{\sqrt{x^2 + y^2}} = 0
\end{equation*}
Osserviamo che $|x| = \sqrt{x^2} \leq \sqrt{x^2 + y^2} = \lVert (x, y) \rVert$. 
Ne consegue che:
\begin{equation*}
	0 \leq \dfrac{x^2}{\lVert (x, y) \rVert} \leq \dfrac{\lVert (x, y) 
	\rVert^2}{\lVert (x, y) \rVert} = \lVert (x, y) \rVert 
	\xrightarrow[(x, y) \to (0, 0)]{} 0
\end{equation*}
Vale quindi il limite. Una cosa che non dimostriamo è che:
\begin{equation*}
	f(x, y) = \text{polinomio omogeneo dei grado p } \implies f(x, y) = 
	o(\lVert (x, y) \rVert^p)
\end{equation*}
Un polinomio omogeneo è un polinomio che ha tutti i termini di grado 
esattamente $p$.

\dfn{
	\textbf{Funzione differenziabile:} Dato $A \subseteq \mathbb{R}^n$ 
	aperto, $x_0 \in A$, $h \in \mathbb{R}^n$ e $f: A \to \mathbb{R}$ si 
	dice che $f$ è \textbf{differenziabile in $x_0$} se:
	\begin{enumerate}
		\item $\exists \partial_1 f, \partial_2 f, \cdots, \partial_nf 
			\in \mathbb{R}$ nel punto $x_0$
		\item Vale la formula:
			\begin{equation*}
				f(x_0 + h) = f(x_0) + \langle \nabla f(x_0), 
				h\rangle +o(\lVert h \rVert) \quad h \to 
				\underline{0} 
			\end{equation*}
	\end{enumerate}
	La 2 si può anche riscrivere con $x = x_0 + h$:
	\begin{equation*}
		f(x) = f(x_0) + \langle \nabla f(x_0), x - x_0 \rangle + 
		o(\lVert x - x_0 \lVert) \quad x \to x_0 
	\end{equation*}
}
Ovviamente la notazione con il prodotto euclideo si può espandere:
\begin{equation*}
	\langle \nabla f(x_0), h \rangle = \partial_1 f \cdot h_1 + \cdots + 
	\partial_n f \cdot h_n = \sum_{k = 1}^n \partial_k f \cdot h_k
\end{equation*}
\imp{
	Se $f:\mathbb{R}^n \to \mathbb{R}$ è differenziabile in $x_0$ il 
	polinomio
	\begin{equation*}
		T_1(x) = f(x_0) + \sum_{k = 1}^n \partial_k f(x_0) 
		\cdot (x - x_0)
	\end{equation*}
	si chiama \textbf{polinomio di Taylor di grado 1 di punto inziale 
	$\mathbf{x_0}$}. Inoltre in $\mathbb{R}^2$ il piano di equazione 
	\begin{equation*}
		z = T_1(x, y)
	\end{equation*}
	risulta essere il \textbf{piano tangente al grafico di $\textbf{f}$} 
	nel punto $(x_0, y_0, f(x_0, y_0))$.
}

%(ESEMPIO CON GRAFICO?)

\thm{
	\textbf{Differenziabile totale:} Data una funzione $f: \mathbb{R}^2 \to 
	\mathbb{R}$ continua, se esistono le sue derivate parziali e sono 
	continue in ogni punto allora $f$ è differenziabile in ogni punto. 
	Cioè:
	\begin{equation*}
		\exists \partial_x f, \partial_y f \text{ continue } 
		\forall x_0 \in \mathbb{R}^2 \implies f \text{ differenziabile } 
		\forall y_0 \in \mathbb{R}^2
	\end{equation*}
}
\imp{
	\textbf{Tutte le funzioni elementari sono differenziabili} in quanto 
	soddisfano la formula di Taylor.
}

Il seguente lemma è necessario alla dimostrazione che segue.
\mlem{
	\textbf{Lagrange per derivate parziali:} Se $f: \mathbb{R}^2 \to 
	\mathbb{R}$ è continua e ha derivate parizali continue, allora:
	\begin{equation*}
		\forall (a, b) \in \mathbb{R}^2, \forall h \in \mathbb{R}, \; 
		\exists \theta \in [0, 1] \,: \; f(a + h, b) - f(a, b) = 
		\partial_x f(a + \theta h, b) h
	\end{equation*}
	Inoltre:
	\begin{equation*}
		\forall (a, b) \in \mathbb{R}^2, \forall k \in \mathbb{R}, \; 
		\exists \theta \in [0, 1] \,: \; f(a, b + k) - f(a, b) = 
		\partial_y f(a, b + \theta k) k
	\end{equation*}

	\textbf{Dimostrazione:}\\
	Definiamo una funzione ausiliaria $g: \mathbb{R} \to \mathbb{R}$ dove 
	$g(x) = f(x, b) \; \forall x \in \mathbb{R}$. Applichiamo ora il 
	teorema di Lagrange per $g$ nell'intervallo di estremi $[a, a + h]$:
	\begin{equation*}
		\exists \theta \in [0, 1]: g(a + h) - g(a) = g'(a + \theta h) 
		(a + h - a)
	\end{equation*}
	Che per definzione di derivata parziale:
	\begin{equation*}
		g'(a + \theta h) \cdot h = \partial_x f(a + \theta h, b) \cdot h
	\end{equation*}
	\hfill Qed.

}
Questo lemma richiama il teorema di Lagrange visto per le funzioni definite in 
$\mathbb{R}^1$, solo che è scritto diversamente. Prendiamo il primo caso, 
quello con la derivata parziale in $x$ e proviamo a riscriverlo: Il punto 
$a + h$ è semplicemente un punto generico che quindi possiamo indicare con 
$A = a + h$. Il punto $a + \theta h$ invece, in quanto $\theta \in [0, 1]$, è 
semplicemente un altro modo di scrivere un punto nell'intervallo $[a, a + h]$. 
Possiamo quindi riscriverlo come $c \in [a, a+h]$, cioè per la sostituzione di 
prima $c \in [a, A]$. Possiamo quindi riscrivere l'enunciato come segue:
\begin{equation*}
	\forall (a, b) \in \mathbb{R}^2, \forall A \in \mathbb{R}, \; \exists c 
	\in [a, A] : f(A, b) - f(a, b) = \partial_x f(c, b) \cdot (A - a)
\end{equation*}
In questo caso abbiamo riscritto $h = A - a$. Se inoltre assumiamo che $A \neq 
a \implies h \neq 0 $, quindi possiamo dividere per $h$:
\begin{equation*}
	\partial_x f(c, b) = \dfrac{f(A, b) - f(a, b)}{A - a}
\end{equation*}
Che se lo confrontiamo con il teorema di Lagrange per le funzioni ad una 
variabile ci assomiglia effettivamente molto:
\begin{equation*}
	f'(c) = \dfrac{f(b) - f(a)}{b - a}
\end{equation*}

Dimostriamo ora il teorema del differenziale totale:
\pf{
	Data $f: \mathbb{R}^2 \to \mathbb{R}$ continua di cui esistono le 
	derivate parziali e sono anche loro continue devo dimostrare che $f$ è 
	differenziabile. Cioè per definzione di funzione differenziabile mi 
	riduco a dimostrare:
	\begin{equation*}
		f(x_0 + h, y_0 + k) = f(x_0, y_0) + \langle \nabla f(x_0, y_0), 
		(h, k) \rangle + o(\lVert (h, k) \rVert)
	\end{equation*}
	Per dimostrare una formula di questo tipo in pratica devo dimostrare 
	che l'o-piccolo è corretto.

	\begin{equation*}
		f(x_0 + h, y_0 + k) - f(x_0, y_0) = \langle \nabla f(x_0, y_0), 
		(h, k) \rangle + o(\lVert (h, k) \rVert)
	\end{equation*}
	Aggiungiamo e sottraiamo alla parte sinistra dell'uguaglianza il fattore 
	$f(x_0 + h, y_0)$:
	\begin{equation*}
		f(x_0 + h, y_0 + k) - f(x_0 + h, y_0) + f(x_0 + h, y_0) - 
		f(x_0, y_0)  = \langle \cdots \rangle + o(\cdots)
	\end{equation*}
	Possiamo raggruppare a due a due i termini identificandoli per 
	comodità nel seguente modo:
	\begin{enumerate}
		\item $f(x_0 + h, y_0 + k) - f(x_0 + h, y_0)$

		\item $f(x_0 + h, y_0) - f(x_0, y_0)$
	\end{enumerate}
	Possiamo ora applicare Langrange per le derivate parziali (cioè il 
	lemma enunciato sopra):\\
	Per 1:
	\begin{equation*}
		\exists \theta_1 \in [0, 1] \, : \; f(x_0 + h, y_0) - 
		f(x_0, y_0) = \partial_x f(x_0 + \theta_1 h, y_0)h
	\end{equation*}
	Per 2:
	\begin{equation*}
		\exists \theta_2 \in [0, 1] \, : \; f(x_0 + h, y_0 + k) - 
		f(x_0 + h, y_0) = \partial_y f(x_0 + h, y_0 + \theta_2 k)k
	\end{equation*}
	La 2 si può riscrivere aggiungendo e sottraendo il termine $\partial_x 
	f(x_0, y_0) h$:
	\begin{align*}
		&\partial_x f(x_0 + \theta_1 h, y_0)h + \partial_x f(x_0, y_0) 
		h - \partial_x f(x_0, y_0) h =\\[5pt]
		= &\; \partial_x f(x_0, y_0) h + [\partial_x f(x_0 + \theta_1 
		h, y_0) - \partial_x f(x_0, y_0) ]h
	\end{align*}
	Stesso discorso per la 1 aggiungendo e sottraendo il termine 
	$\partial_y f(x_0, y_0) k$:
	\begin{equation*}
		\partial_y f(x_0, y_0) k + [\partial_y f(x_0 + h, y_0 + 
		\theta_2 k) - \partial_y f(x_0, y_0)]k
	\end{equation*}
	I fattori che abbiamo aggiunto non sono scelti a caso ma bensì sono lo 
	sviluppo del prodotto scalare euclideo presente nella formula inziale. 
	Riscrviamo la formula iniziale:
	\begin{equation*}
		f(x_0 + h, y_0 + k) - f(x_0, y_0) = \langle \nabla f(x_0, y_0), 
		(h, k) \rangle + o(\lVert (h, k) \rVert)\\
	\end{equation*}
	Sotituendo le espansioni di 1 e 2 ed espandendo il prodotto scalare 
	euclideo:
	\begin{align*}
		&\partial_x f(x_0, y_0) h + [\partial_x f(x_0 + \theta_1 h, y_0) 
		- \partial_x f(x_0, y_0) ]h +\\[2pt]
		&\partial_y f(x_0, y_0) k + [\partial_y f(x_0 + h, y_0 + 
		\theta_2 k) - \partial_y f(x_0, y_0)]k \\[2pt]
		=& \partial_x f(x_0, y_0) h + \partial_y f(x_0, y_0) k + 
		o(\lVert (h, k) \rVert)\\
	\end{align*}
	Semplificando i termini uguali da entrambe le parti dell'equazine 
	diventa:
	\begin{equation*}
		[\partial_x f(x_0 + \theta_1 h, y_0) - \partial_x f(x_0, y_0) ]h 
		+ [\partial_y f(x_0 + h, y_0 + \theta_2 k) - \partial_y f(x_0, 
		y_0)]k = o(\lVert (h, k) \rVert)
	\end{equation*}
	Ci basta quindi far vedere che tutto quello nelle parentesi quadre è 
	effettivamente un o-piccolo della norma di $(h, k)$. Per la definzione 
	di o-piccolo devo dimostrare che (vale la stessa cosa per l'altra 
	parentesi quadra):
	\begin{equation*}
		\dfrac{[\partial_x f(x_0 + \theta_1 h, y_0) - \partial_x 
		f(x_0, y_0) ]h}{\lVert (h, k) \rVert} \xrightarrow[(h, k) \to 
		(0, 0)] {} 0
	\end{equation*}
	In quanto:
	\begin{equation*}
		\left | \dfrac{h}{\lVert (h, k) \rVert} \right | < \dfrac{\lVert 
		(h, k) \rVert}{\lVert (h, k) \rVert} = 1
	\end{equation*}
	Mi basta quindi mostrare che:
	\begin{equation*}
		[\partial_x f(x_0 + \theta_1 h, y_0) - \partial_x f(x_0, y_0) ] 
		\xrightarrow[(h, k) \to (0, 0)]{} 0
	\end{equation*}
	Prendiamo una successione $(h_n, k_n) \to (0, 0)$ e calcoliamo il 
	limite:
	\begin{equation*}
		\lim_{n \to +\infty} \partial_x f(x_0 + \theta_1 h_n, y_0) - 
		\partial_x f(x_0, y_0) =
	\end{equation*}
	Essedo per ipotesi $\partial_x f$ continua $(x_0 + \theta_1 h_n, y_0) 
	\xrightarrow[h_n \to 0]{} (x_0, y_0)$:
	\begin{equation*}
		= \partial_x f(x_0, y_0) - \partial_x f(x_0, y_0) = 0
	\end{equation*}
	\hfill Qed.
}

Il teorema appena enunciato vale anche con l'implicazione contraria. Questa 
però è una proposizione più che un vero e proprio teorema:

\imp{
	\textbf{PROP:} Se $f: \mathbb{R}^2 \to \mathbb{R}$ è differenziabile 
	in $(x_0, y_0)$ allora $f$ è continua in $(x_0, y_0)$.
}
\pf{
	Dimostro la proprozione appena enunciata: Suppongo che $f$ sia 
	differenziabile in $(x_0, y_0)$ e dimostro che $f$ è continua in 
	$(x_0, y_0)$. Cioè che presa una successione $(x_n, y_n) 
	\xrightarrow[n \to +\infty]{} (x_0, y_0)$ deve valere il limite:
	\begin{equation*}
		\lim_{n \to +\infty} f(x_n, y_n) = f(x_0, y_0)
	\end{equation*}
	Essendo che per ipotesi $f$ è diffirenziabile in $(x_0, y_0)$ vale la 
	formula di Taylor:
	\begin{equation*}
		f(x_n, y_n) = f(x_0, y_0) + \langle \nabla f(x_0, y_0), 
		(x_n - x_0, y_n - y_0) \rangle + o(\lVert (x_n - x_0, y_n - 
		y_0) \rVert)
	\end{equation*}
	Sostituendo nel limite:
	\begin{align*}
		&\lim_{n \to +\infty} f(x_0, y_0) + \langle \nabla f(x_0, y_0), 
		(x_n - x_0, y_n - y_0) \rangle + o(\lVert (x_n - x_0, y_n - y_0) 
		\rVert) =\\
		= &\lim_{n \to +\infty} f(x_0, y_0) + \langle \nabla 
		f(x_0, y_0), (x_0 - x_0, y_0 - y_0) \rangle + o(\lVert 
		(x_0 - x_0, y_0 - y_0) \rVert) =\\
		= &\lim_{n \to +\infty} f(x_0, y_0) + \langle \nabla 
		f(x_0, y_0), (0, 0) \rangle + o(\lVert (0, 0) \rVert) = 
		\lim_{n \to +\infty} f(x_0, y_0) = f(x_0, y_0)
	\end{align*}
	\hfill Qed.
}

\subsection{Derivate direzionali di funzioni scalari}
\dfn{
	Sia $f: \mathbb{R}^n \to \mathbb{R}$, $x_0 \in \mathbb{R}^n$ e $v \in 
	\mathbb{R}^n$ con $\lVert v \rVert = 1$. \textbf{La derivata 
	direzionale} di $f$ in $x_0$ nella direzione  $v$ è il limite (se 
	esiste finito): 
	\begin{equation*}
		\pdv{f}{v} (x_0) \vcentcolon = \lim_{t \to 0} \dfrac{f(x_0 + t 
		\cdot v) - f(x_0)}{t}
	\end{equation*}
	Un altro per indicare la derivata dirazionale di $f$ in $x_0$ lungo la 
	direzione $v$ è: $\partial_v f(x_0)$
}
Notiamo che le derivate parziali sono un caso speciale della derivata 
direzionale: esse infatti si formano usando come vettore $v$ un vettore 
coordinato della base di $\mathbb{R}^n$. Se infatti scegliamo $v = (1, 0, 
\cdots, 0) = e_1$:
\begin{equation*}
	\lim_{t \to 0} \dfrac{f((x_0) + t \cdot (1, 0, \cdots, 0)) - f(x_0)}{t} 
	= \pdv{f}{x_1} (x_0)
\end{equation*}

\imp{
	Data $f: \mathbb{R}^n \to \mathbb{R}$, $x_0 \in \mathbb{R}^n$ e $v \in 
	\mathbb{R}^n \setminus \underline{0}$ con $\lVert v \rVert = 1$. Se 
	prendiamo la funzione $g: \mathbb{R} \to \mathbb{R}$ definita come:
	\begin{equation*}
		g(t) = f(x_0 + t \cdot v)
	\end{equation*}
	Possiamo osservare che:
	\begin{equation*}
		g'(0) = \pdv{f}{v}(x_0)
	\end{equation*}
	Infatti:
	\begin{equation*}
		g'(0) = \lim_{t \to 0 } \dfrac{g(t) - g(0)}{t} = \lim_{t \to 0} 
		\dfrac{f(x_0 + t \cdot v) - f(x_0)}{t} = \partial_v f(x_0)
	\end{equation*}
}
Questa piccola osservazione aiuta i calcoli, questo perché per calcolare una 
derivata direzionale di una funzione in $\mathbb{R}^n$ ci riduciamo 
semplicemente al calcolo della derivata di una funzione in $\mathbb{R}^1$. 
Esempio: Data la funzione $f(x, y) = xy^2$ vogliamo calcolare $\partial_v 
(1, 2)$ con $v$ generico:
\begin{equation*}
	g(t) = f(1 + tv_1, 2 + tv_2) = (1 + tv_1)(2 + tv_2)^2
\end{equation*}
Quindi la derivata ora:
\begin{equation*}
	g'(t) = v_1(2 + tv_2)^2 + (1+tv_1) \cdot 2 \cdot (2 + tv_2) \cdot v_2
\end{equation*}
Per calcolare quindi $\partial_v f(1, 2)$ ci basta semplicemente calcolare 
$g'(0)$:
\begin{equation*}
	g'(0) = v_1 \cdot 2^2 + 1 \cdot 2 \cdot 2 \cdot v_2 = 4v_1 + 4v_2 = 
	4(v_1 + v_2)
\end{equation*}

\thm{
	\textbf{Teorema delle derivate direzionali:} Data $f: \mathbb{R}^n \to 
	\mathbb{R}$, $x_0 \in \mathbb{R}^n$ e $v \in \mathbb{R}^n$ con $\lVert 
	v \rVert = 1$. Se $f$ è differenziabile in $x_0$ allora vale:
	\begin{equation*}
		\pdv{f}{v}(x_0) = \langle \nabla f(x_0), v \rangle = 
		\sum_{i = 1}^n \pdv{f}{x_i}(x_0) \cdot v_i
	\end{equation*}
	Questo implica che la derivata direzionale \textbf{è sempre lineare 
	rispetto a $\mathbf{v}$}.
}

\pf{
	Dalla definzione di derivata direzionale:
	\begin{equation*}
		\pdv{f}{v} (x_0) = \lim_{t \to 0} \dfrac{f(x_0 + t \cdot v) - 
		f(x_0)}{t}
	\end{equation*}
	Essendo la funzione differenziabile in $x_0$ per ipotesi vale la formula 
	di Taylor:
	\begin{equation*}
		f(x_0 + t \cdot v) - f(x_0) = \langle \nabla f(x_0), t \cdot v 
		\rangle + o(\lVert t \cdot v \rVert)
	\end{equation*}
	Notiamo che: 
	\begin{equation*}
		o(\lVert t \cdot v \rVert) = o(|t| \cdot \lVert v \rVert)
	\end{equation*}
	Ed essendo per ipotesi $\lVert v \rVert = 1$ l'o-piccolo diventa $o(t)$. 
	Riportiamo la formula di Taylor sopra il limite:
	\begin{equation*}
		\lim_{t \to 0} \dfrac{\langle \nabla f(x_0), t \cdot v \rangle 
		+ o(t)}{t} = \lim_{t \to 0} \left (\langle \nabla f(x_0), v 
		\rangle + \dfrac{o(t)}{t} \right) = \langle \nabla f(x_0), v 
		\rangle
	\end{equation*}
	\hfill Qed.
}

% IL PROF FA UN ESEMPIO CON UNA FUNZIONE STRANA MA NON HO CAPITO PERCHÈ. 
% (FOGLIO 10+ FILE 2023-03-29)

\subsubsection{Direzione di massima crescita}
Avendo definito la derivata direzionale per una funzione in un punto, ora 
possiamo derivare tale funzione in infinite direzioni date dal versore $v$. 
Chiediamoci qual'è la direzione che massimizza la derivata, cioè la direzione 
che massimizza la crescita delle funzione. Prendiamo quindi una funzione 
generica $f: \mathbb{R}^2 \to \mathbb{R}$ differenziabile nel punto $(x_0, y_0) 
\in \mathbb{R}^2$. Per evitare banalità $\nabla f(x_0, y_0) \neq \underline{0}$ 
in quanto se il gradiente fosse nullo $\partial_v f = 0 \; \forall v$. Volgiamo 
quindi massimizzare la quantità:
\begin{equation*}
	\pdv{f}{v}(x_0, y_0)
\end{equation*}
Per farlo passiamo alle coordinate polari. Il gradiente risulta quindi:
\begin{equation*}
	\nabla f(x_0, y_0) = (r\cos(\phi), r\sin(\phi)) \quad \text{dove} 
	\quad r = \lVert \nabla f(x_0, y_0) \rVert \quad q \in [0, 2\pi]
\end{equation*}
Il versore $v$, in quanto unitario per la definzione di derivata direzionale:
\begin{equation*}
	v = (\cos(\theta), \sin(\theta)) \quad \theta \in [0, 2\pi]
\end{equation*}
Calcoliamo quindi la derivata direzionale, che per il teorema delle derivate 
direzionali risulta:
\begin{align*}
	\pdv{f}{v}(x_0, y_0) &= \langle \nabla f(x_0, y_0), (v_1, v_2) \rangle 
	= \langle (r\cos(\phi), r\sin(\phi)), (\cos(\theta), \sin(\theta)) 
	\rangle =\\
	&= r\cos(\phi)\cos(\theta) + r\sin(\phi)\sin(\theta) = r \cos(\phi - 
	\theta)
\end{align*}
Per rendere massima quindi l'espressione $r \cos(\phi - \theta)$ il coseno deve 
essere uguale a $1$. Quindi:
\begin{equation*}
	\theta = \phi
\end{equation*}
Questo implica che il versore di massima crescia ha la stessa direzione del 
gradiente\footnote{Questo fatto vale anche in $\mathbb{R}^n$. Per dimostrarlo 
però non si può fare uso delle coordinate polari e bisogna prendere un'altra 
strada}. Inoltre essendo che $\theta = \phi$:
\begin{equation*}
	\pdv{f}{v}(x_0, y_0) = r\cos(\phi - \theta) = r\cos(\phi - \phi) = r = 
	\lVert \nabla f(x_0, y_0) \rVert
\end{equation*}
Tornando un attimo alla formula:
\begin{equation*}
	\pdv{f}{v}(x_0, y_0) = r \cos(\phi - \theta)
\end{equation*}
Notiamo che se $\phi - \theta = \frac{\pi}{2}$, cioè in pratica il versore $v$ 
è perpendicolare\footnote{Questo perché appunto $r\cos(\phi - \theta)$ è dato 
dal prodotto scalare euclideo tra il gradiente $\nabla f(x_0, y_0)$ e il 
versore $v$. Ne consegue che per definizione di ortogonalità il gradiente e il 
versore $v$ sono perpendicolari in quanto questo prodotto è nullo.} al 
gradiente $\nabla f(x_0. y_0)$, si ha che la derivata è sempre nulla:
\begin{equation*}
	\pdv{f}{v}(x_0, y_0) = r \cos\dfrac{\pi}{2} = 0
\end{equation*}
Essendo la derivata sempre nulla significa che la funzione è costante lungo 
quella direzione: ci troviamo quindi lungo una linea di livello. Ne consegue 
che, essendo $v$ lungo la linea di livello ed essendo $\nabla f(x_0, y_0) \perp 
v$, allora il gradiente è perpendicolare alla linea di livello. Facendo un 
riassunto:
\imp{
	Data una funzione $f: \mathbb{R}^n \to \mathbb{R}$ differenziabile in 
	un punto $x_0 \in \mathbb{R}^n$. Il versore $v$ che massimizza 
	$\partial_v f (x_0)$ lo denotimo con $v_{\text{max}}$ ed è il 
	normalizzato del gradiente nel punto $x_0$:
	\begin{equation*}
		v_{\text{max}} = \dfrac{\nabla f(x_0)}{\lVert \nabla f(x_0) 
		\rVert}
	\end{equation*}
	Inoltre vale che:
	\begin{equation*}
		\pdv{f}{v_{\text{max}}}(x_0) = \lVert \nabla f(x_0) \rVert
	\end{equation*}
	E il gradiente è sempre ortogonale all'insieme di livello della funzione 
	che comprende il punto $b = f(x_0)$. Cioè l'insieme:
	\begin{equation*}
		L_{b} = \{x \in \mathbb{R}^n | f(x) = b = f(x_0)\}
	\end{equation*}
}

\subsection{Derivata di una curva}
\dfn{
	\textbf{Velocità di una curva}: Data $r:]a,b[ \to \mathbb{R}^n$ definita 
	come:
	\begin{equation*}
		t \mapsto r(t) = (r_1(t), \cdots, r_n(t))
	\end{equation*}
	La velocità del punto $t_0$ è:
	\begin{equation*}
		r'(t_0) = (r'_1(t_0), \cdots, r'_n(t_0))
	\end{equation*}
	Quest'ultimo si chiama vettore velocità e rappresenta la tangente alla 
	curva nel punto $t_0$. Possiamo anche evitare la sostituzione del punto 
	$t_0$ e quindi ottenere la funzione velocità.
}
Tornando infatti alle funzioni di prima le velocità sono diverse:
\begin{align*}
	r'(t) =& (-\sin(t), \cos(t))\\
	f(t) =& (-\sin(t^3) \cdot 3t^2, \cos(t^3) \cdot 3t^2)
\end{align*}
Mentre infatti $r(t)$ e $f(t)$  descrivono lo stesso insieme di punti al 
variare di $t$, le loro velocità no.

\dfn{
	\textbf{Velocità scalare:} Data $f: \mathbb{R} \to \mathbb{R}^n$ si 
	definisce la velocità scalare al tempo $t_0$ lo scalare:
	\begin{equation*}
		\lVert r'(t_0) \rVert
	\end{equation*}
}

Possiamo definire la \textbf{formula di Taylor} per le curve: se $t \in ]a, b[$
\begin{equation*}
	\begin{cases}
		r_1(t + h) = r_1(t) + r_1'(t)h + o_1(h)\\
		\vdots\\
		r_n(t + h) = r_n(t) + r_n'(t)h + o_n(h)\\
	\end{cases}
\end{equation*}
Possiamo anche scrivere in modo più compatto:
\begin{equation*}
	r(t + h) = r(t) + r'(t)h + o(h)\\
\end{equation*}

\dfn{
	\textbf{Lunghezza di una curva}: Data $r: \mathbb{R} \to \mathbb{R}^n$ 
	dove $t \to r(t) \in \mathbb{R}^n$ sia $[a,b] \in \subseteq{R}$, 
	supponiamo che $r'(t) \neq \underline{0} \; \forall t$. La lunghezza 
	del tratto di curva tra $r(a)$ e $r(b)$ vale:
	\begin{equation*}
		\text{Length}(a, b) = \int_a^b \lVert r'(t) \rVert \diff t
	\end{equation*}
}
Esempio 1: Prediamo la funzione $r(t) = (\cos(t), \sin(t))$ e calcoliamo la 
lunghezza nell'intervallo $[0, 2\pi]$. Essendo una circonferenza il valore che 
ci aspettimo è proprio la lunghezza di quest'ultima:
\begin{equation*}
	\int_0^{2\pi} \lVert r'(t) \rVert \diff t = \int_0^{2\pi} \lVert (
	-\sin(t), \cos(t)) \rVert \diff t = \int_0^{2\pi} \sqrt{\sin^2(t) + 
	\cos^2(t)} \diff t = \int_0^{2\pi} 1 \diff t =  [t]_0^{2\pi} = 2\pi
\end{equation*}
Esempio 2: Prediamo la funzione $r(t) = (\cos(t^2), \sin(t^2))$ e calcoliamo 
la lunghezza nell'intervallo $[0, \sqrt{2\pi}]$. La funzione nell'intervallo 
ristretto descrive sempre una circonferenza, quello che cambia è però la sua 
velocità:
\begin{align*}
	\int_0^{\sqrt{2\pi}} \lVert r'(t) \rVert \diff t = \int_0^{\sqrt{2\pi}} 
	\lVert (-\sin(t^2) \cdot 2t, \cos(t^2) \cdot 2t) \rVert \diff t = 
	\int_0^{\sqrt{2\pi}} \sqrt{4t^2(\sin^2(t) + \cos^2(t))} \diff t = \\
	= \int_0^{\sqrt{2\pi}} 2t \diff t =  [t^2]_0^{\sqrt{2\pi}} = 2\pi
\end{align*}
Notiamo però che nonostante la velocita sia diversa la lunghezza rimane la 
stessa. Questo significa che \textbf{la lunghezza non dipende dalla 
parametrizzazione}\footnote{Il prof ha detto che non è molto rigorosa come 
affermazione, ma per noi va più che bene}.

\subsection{Derivata funzioni composte} \label{theorem_derivateComposte}
\thm{
	\textbf{Derivata lungo una curva}: Data $f: \mathbb{R}^n \to 
	\mathbb{R}$ differenziabile e $r: \mathbb{R} \to \mathbb{R}^n$ 
	derivabile. Allora è definita la funzione:
	\begin{equation*}
		(f \circ r)(t) = f(r(t)) \quad \forall(t) \in \mathbb{R}
	\end{equation*}
	Tale funzione è derivabile $\forall t \in \mathbb{R}$ e vale:
	\begin{equation*}
		\odv{}{t} f(r(t)) = \langle \nabla f(r(t)), r'(t) \rangle
	\end{equation*}
	Questo implica che la derivata \textbf{è lineare rispetto alla 
	velocità}, cioè rispetto al vettore $r'(t)$.
}
Notiamo che se prendiamo una funzione generica $f: \mathbb{R}^n \to 
\mathbb{R}$ e una funzione $r(t) = x + tv$ dove $x, v \in \mathbb{R}^n$ e 
$\lVert v \rVert = 1$ possiamo calcolare la derivata in 0. La compisizione 
delle due funzioni risulta:
\begin{equation*}
	(f \circ r)(t) = f(x + tv) 
\end{equation*}
Dal teorema appena enunciato la derivata in 0 risulterebbe quindi:
\begin{equation*}
	(f \circ r)'(0) = \langle \nabla f(r(0)), r'(0) \rangle = \langle 
	\nabla f(0), v \rangle 
\end{equation*}
Se invece usassimo la definzione di derivata per la funzione $g(t) = f(x + tv)$ 
verebbe:
\begin{equation*}
	g'(0) = \lim_{h \to 0} \dfrac{g(h) - g(0)}{h} = \lim_{h \to 0} 
	\dfrac{f(x + hv) - f(x)}{h} = \pdv{f}{v} (x) = \langle \nabla f(0), v 
	\rangle
\end{equation*}
Notiamo che il risultato è esattamente lo stesso.
\pf{
	Assumiamo che $f$ sia differenziabile e $r$ derivabile nei loro 
	rispettivi domini. Vogliamo dimostrare che:
	\begin{equation*}
		\odv{}{t} f(r(t)) = \langle \nabla f(r(t)), r'(t) \rangle
	\end{equation*}
	Iniziamo con espandere la definzione di derivata:
	\begin{equation*}
		\odv{}{t} f(r(t)) = \lim_{h \to 0}  \dfrac{f(r(t + h)) - 
		f(r(t))}{h}
	\end{equation*}
	Ricodandoci le formule di Taylor per le curve:
	\begin{equation*}
		r(t + h) = r(t) + r'(t)h + o(h) \quad h \to 0
	\end{equation*}
	E quindi:
	\begin{equation*}
		r(t + h) - r(t) = r'(t)h + o(h) \quad h \to 0
	\end{equation*}
	Ricordandoci inoltre Taylor per le funzioni in più variabili:
	\begin{equation*}
		f(x + h) = f(x) + \langle \nabla f(x), h \rangle + o(\lVert h 
		\rVert)
	\end{equation*}
	Ora applichiamo la formula di Taylor al numeratore della nostra 
	derivata:
	\begin{equation*}
		f(r(t + h)) -f(r(t)) = \langle \nabla f(r(t)), r(t + h) - r(t) 
		\rangle + o(\lVert r(t + h) - r(t) \rVert) =
	\end{equation*}
	Sostituendo ora l'espressione $r(t + h) - r(t)$ con la formula di 
	Taylor scritta sopra:
	\begin{equation*}
		= \langle \nabla f(r(t)), r'(t)h + o(h) \rangle + o(\lVert 
		r'(t)h + o(h) \rVert) =
	\end{equation*}
	Usando la linearità del prodotto scalare:
	\begin{equation*}
		= \langle \nabla f(r(t)), r'(t) \rangle \cdot h + \langle 
		\nabla f(r(t)), o(h) \rangle + o(\lVert r'(t)h + o(h) \rVert)
	\end{equation*}
	Riprendiamo il limite che dobbiamo calcolare e sostituiamo il 
	numeratore:
	\begin{equation*}
		\lim_{h \to 0}  \dfrac{\langle \nabla f(r(t)), r'(t) \rangle 
		\cdot h + \langle \nabla f(r(t)), o(h) \rangle + o(\lVert 
		r'(t)h + o(h) \rVert)}{h}
	\end{equation*}
	Nel primo fattore il termine $h$ si semplifica mentre negli alti due il 
	rapporto con $h$ manda banalmente tutto a zero:
	\begin{align*}
		= &\lim_{h \to 0}  \dfrac{\langle \nabla f(r(t)), r'(t) \rangle 
		\cdot h}{h} + \dfrac{\langle \nabla f(r(t)), o(h) \rangle}{h} + 
		\dfrac{o(\lVert r'(t)h + o(h) \rVert)}{h} =\\[5pt]
		= &\lim_{h \to 0} \langle \nabla f(r(t)), r'(t) \rangle + 0 + 0 
		= \langle \nabla f(r(t)), r'(t) \rangle
	\end{align*}
	\hfill Qed.
}
Gradiente e insiemi di livello: Se prendiamo una funzione $f: \mathbb{R}^2 \to 
\mathbb{R}$ e un punto $b \in \mathbb{R}$ l'insieme di livello associeto 
risutla:
\begin{equation*}
	L_b = f^{-1}(b) = \{(x, y) \in \mathbb{R} | f(x, y) = b\}
\end{equation*}
Supponiamo per comodità $\nabla f(x, y) \neq \underline{0} \;\; \forall (x, y)$. 
Supponiamo inoltre di poter costruire una curva $r: \mathbb{R} \to 
\mathbb{R}^2$ t.c. $r(t) \in L_b \; \forall t$ e $r'(t) \neq \underline{0}$. 
Se ora applichiamo la nostra funzione iniziale $f$ alla curva oteniamo che:
\begin{equation*}
	f(r(t)) = b \quad \forall t \in \mathbb{R}
\end{equation*}
Questo significa che è costante e quindi:
\begin{equation*}
	\odv{}{t} f(r(t)) = 0 \quad \forall t
\end{equation*}
Per il teorema precedente:
\begin{equation*}
	\langle \nabla f(r(t)), r'(t)h \rangle = 0
\end{equation*}
Ne consegue quindi che $\nabla f(r(t))$ è ortogonale a $r'(t)$.

\subsection{Derivate parziali seconde}
Come nel caso di $\mathbb{R}^1$ in cui si poteva considerare la derivata prima 
come una funzione e quindi derivarla nuovamente, anche in $\mathbb{R}^2$ è 
possibile considerare le derivate parziali come funzioni e quindi applicare 
nuovamente l'operatore di derivata. Per esempio se abbiamo la funzione $f = x^2 
+ xy^3$ possiamo calcolare le sue derivate pariziali:
\begin{equation*}
	\begin{cases}
		\displaystyle \pdv{f}{x} (x, y) = 2x + y^3\\[10pt]
		\displaystyle \pdv{f}{y} f(x, y) = 3xy^2
	\end{cases}
\end{equation*}
Ora se consideriamo le derivate prime come delle funzioni possiamo calcolare 
le derivate seconde, anche questa volta parziali:
\begin{equation*}
	\begin{cases}
		\displaystyle \pdv{}{x} \pdv{f}{x}(x, y) = 2\\[10pt]
		\displaystyle \pdv{}{x} \pdv{f}{y}(x, y) = 3y^2\\[10pt]
		\displaystyle \pdv{}{y} \pdv{f}{x}(x, y) = 3y^2\\[10pt]
		\displaystyle \pdv{}{y} \pdv{f}{y}(x, y) = 6xy
	\end{cases}
\end{equation*}
Le derivate rispetto alla stessa variabile vengono generalemente indicate come 
\textbf{derivate quadrate} o pure, mentre le altre come semplici 
\textbf{derivate miste}. Si usano di solito varie convenzioni per evitare di 
scrivere due volte la frazione per le derivate seconde: 
\begin{equation*}
	\begin{cases}
		\displaystyle \pdv[order=2]{f}{x}(x, y) \vcentcolon = 
		\displaystyle \pdv{}{x} \pdv{f}{x}(x, y) \\[10pt]
		\displaystyle \pdv{f}{x,y}(x, y) \vcentcolon = \displaystyle 
		\pdv{}{x} \pdv{f}{y}(x, y) \\[10pt]
		\displaystyle \pdv{f}{y,x}(x, y) \vcentcolon = \displaystyle 
		\pdv{}{y} \pdv{f}{x}(x, y) \\[10pt]
		\displaystyle \pdv[order=2]{f}{y}(x, y) \vcentcolon = 
		\displaystyle \pdv{}{y} \pdv{f}{y}(x, y) 
	\end{cases}
\end{equation*}

Come possiamo notare dall'esempio risportato sopra le derivate miste hanno lo 
stesso risultato. Questo non è un semplice caso:
\thm{
	\textbf{Teorema di Schwarz:} Dato $A \subseteq \mathbb{R}^n$ e $f: A 
	\to \mathbb{R}^n$. Se $f$ ha tutte le derivate seconde continue, allora 
	vale che:
	\begin{equation*}
		\pdv{f}{x_j, x_k} = \pdv{f}{x_k, x_j} \quad \forall j,k \in 
		\{1, \cdots, n\}
	\end{equation*}
	Per le derivate miste quindi \textbf{non conta l'ordine di derivazione}.
}
Se prendiamo quindi una funzione $f(x, y, z) = x^3 y e^{5z}$ e proiamo a 
calcolare due derivate miste:
\begin{equation*}
	\pdv{f}{x} = 3x^2 y e^{5z} \qquad \pdv{f}{x, z} = 15x^2 y e^{5z} 
\end{equation*}

\begin{equation*}
	\pdv{f}{z} = 5x^3 y e^{5z} \qquad \pdv{f}{z, x} = 15x^2 y e^{5z} 
\end{equation*}

\dfn{
	\textbf{Matrice Hessiana}: Dato $A \subseteq \mathbb{R}^n$ e $f: A \to 
	\mathbb{R}^n$ con derivate seconde continue, possiamo raggruppare le 
	derivate seconde in una matrice quadrata detta matrice Hessiana e 
	indicato con:
	\begin{equation*}
		\mathbf{H}f(x) \in M_{n \times n} (\mathbb{R}) = \mathbb{R}^{n 
		\times n}
	\end{equation*}
	E i cui elementi sono:
	\begin{equation*}
		(\mathbf{H}f(x))_{jk} = \pdv{f}{x_j, x_k}(x)
	\end{equation*}
	In forma leggermente più esplicita risulta:
	\begin{equation*}
		\mathbf{H}f(x) =
		\begin{bmatrix}
			\displaystyle \pdv{f}{x_1, x_1} & \displaystyle \pdv{f}
			{x_1, x_2} & \dots &\displaystyle \pdv{f}{x_1, x_n}
			\\[10pt]
			\displaystyle \pdv{f}{x_2, x_1} & \displaystyle \pdv{f}
			{x_2, x_2} & \dots &\displaystyle \pdv{f}{x_2, x_n}
			\\[10pt]
			\vdots & \vdots & \ddots & \vdots\\[10pt]
			\displaystyle \pdv{f}{x_n, x_1} & \displaystyle \pdv{f}
			{x_n, x_2} & \dots &\displaystyle \pdv{f}{x_n, x_n}
		\end{bmatrix}
	\end{equation*}
	Per il teorema di Schwarz la matrice è \textbf{simmetrica}.
}
\dfn{
	Una matrice $\mathbf{A} \in \mathbb{R}^{n \times n}$ si dice 
	\textbf{simmetrica} se è uguale alla sua trasposta:
	\begin{equation*}
		\mathbf{A} = \mathbf{A}^T
	\end{equation*}
}
In $\mathbb{R}^2$ la matrice Hessiana assume la seguente forma:
\begin{equation*}
	\mathbf{H}f(x) =
	\begin{bmatrix}
		\displaystyle \pdv[order=2]{f}{x} & \displaystyle \pdv{f}{x, y}
		\\[10pt]
		\displaystyle \pdv{f}{y, x} & \displaystyle \pdv[order=2]{f}{x}
	\end{bmatrix}
\end{equation*}
Quindi per la funzione considera all'inzio di questa sezione, cioè $f = x^2 + 
xy^3$ la matrice Hessiana risulta essere:
\begin{equation*}
	\mathbf{H}f(x) =
	\begin{bmatrix}
		2 & 3y^2\\
		3y^2 & 6xy
	\end{bmatrix}
\end{equation*}
E come abbiamo visto dal teorema di Schwarz è simmetrica.

\subsubsection{Forme quadratiche}
\dfn{
	\textbf{Forma quadratica}: Sia $\mathbf{A} \in \mathbb{R}^{n \times n}$ 
	e $\mathbf{A} = \mathbf{A}^T$. La forma quadratica associata ad 
	$\mathbf{A}$ è la funzione $q: \mathbb{R}^n \to \mathbb{R}$ definita 
	come:
	\begin{equation*}
		q(h) = \langle \mathbf{A}h, h \rangle \qquad \forall h \in 
		\mathbb{R}^n
	\end{equation*}
}
Esempio in $\mathbb{R}^2$: Prendiamo la matrice $\mathbf{A}$ che risulta essere 
(in quanto simmetrica):
\begin{equation*}
	A =
	\begin{bmatrix}
		a & b\\
		b & c
	\end{bmatrix}
\end{equation*}
La forma quadratica associata risulta quindi essere:
\begin{align*}
	q(h_1, h_2) =&
	\langle 
	\begin{bmatrix}
		a & b\\
		b & c
	\end{bmatrix}
	\begin{bmatrix}
		h_1\\
		h_2
	\end{bmatrix},
	\begin{bmatrix}
		h_1\\
		h_2
	\end{bmatrix}
	\rangle = 
	\langle
	\begin{bmatrix}
		ah_1 + bh_2\\
		bh_1 + ch_2
	\end{bmatrix},
	\begin{bmatrix}
		h_1\\
		h_2
	\end{bmatrix}
	\rangle =
	ah_1^2 + bh_1h_2 + bh_1h_2 + ch_2^2 \\[5pt]
	=& ah_1^2 + 2bh_1h_2 + ch_2^2
\end{align*}
Il risultato è un polinomio omogeneo di grado 2 che assomiglia molto ad un 
quadrato di binomio (sarà da qui che viene il nome?). Nel caso di 
$\mathbb{R}^3$ siulta invece:
\begin{align*}
	q(h_1, h_2, h_3) =&
	\langle 
	\begin{bmatrix}
		a & b & c\\
		b & d & e\\
		c & e & f
	\end{bmatrix}
	\begin{bmatrix}
		h_1\\
		h_2\\
		h_3
	\end{bmatrix},
	\begin{bmatrix}
		h_1\\
		h_2\\
		h_3
	\end{bmatrix}
	\rangle = 
	\langle 
	\begin{bmatrix}
		ah_1 + bh_2 + ch_3\\
		bh_1 + dh_2 + eh_3\\
		ch_1 + eh_2 + fh_3
	\end{bmatrix},
	\begin{bmatrix}
		h_1\\
		h_2\\
		h_3
	\end{bmatrix}
	\rangle =\\[5pt]
	=& ah_1^2 + bh_1h_2 + ch_1h_3 + bh_1h_2 + dh_2^2 + eh_2h_3 + ch_1h_3 + 
	eh_2h_3 + fh_3^2 =\\
	=& ah_1^2 + dh_2^2 + fh_3^2 + 2bh_1h_2 + 2ch_1h_3 + 2eh_2h_3 
\end{align*}
Possiamo anche riscrivere la forma quadratica tramite la sommatoria:
\begin{equation*}
	\langle \mathbf{A}h, h \rangle = \sum_{j = 1}^n (\mathbf{A}h)_j \cdot 
	h_j = \sum_{j = 1}^n \left(\sum_{k = 1}^n a_{jk}h_k \right)_j \cdot h_j 
	= \sum_{j,k = 1}^n a_{jk}h_kh_j
\end{equation*}
In questo caso si nota ancora di più il fatto che il polinomio è omogeneo e ha 
grado 2.

\dfn{
	\textbf{Segno di forme quadratiche:} Sia $A = A^T \in \mathbb{R}^{n 
	\times n}$ simmetrica e la sua forma quadratica associata $q$. Si dice 
	che:
	\begin{itemize}
		\item $A$ è \textit{definita positiva} ($A > 0$) se vale 
			$\langle Ah, h \rangle > 0 \;\; \forall h \in 
			\mathbb{R}^n \setminus \{\underline{0}\}$

		\item $A$ è \textit{definita negativa} ($A < 0$) se vale 
			$\langle Ah, h \rangle < 0 \;\; \forall h \in 
			\mathbb{R}^n \setminus \{\underline{0}\}$

		\item $A$ è \textit{indefinita} se esistono $h_-, h_+ 
			\in \mathbb{R}^n$ tali che $\langle Ah_-, h_- \rangle 
			< 0 < \langle Ah_+, h_+ \rangle $
	\end{itemize}
	Da notare che le disiguaglianze sono strette.
}
\thm{
	\textbf{Classificazione forme quadratiche non degeneri 2x2:} Se $A = 
	A^T = \begin{bmatrix} a & b\\ b & c \end{bmatrix} \in \mathbb{R}^{2 
	\time 2}$, allora:
	\begin{itemize}
		\item $A > 0$ sse $a > 0$ e $\text{det}(A) > 0$
		\item $A < 0$ sse $a < 0$ e $\text{det}(A) > 0$
		\item $A$ è indefinita sse $\text{det}(A) < 0$
	\end{itemize}
	DIMOSTRAZIONE? Inoltre sugli appunti del 2023-04-20 è presente tutta una
	parte in cui vengono discusse le forme quadratiche in relazione agli 
	autovalori. Tale parte non è presente sugli appunti del prof però e non
	sembra richiesta all'esame.
}

\subsection{Taylor di ordine 2 con resto secondo Lagrange}
La forma classica della formula di Taylor al secondo ordine è:
\begin{equation*}
	f(x_0 + h) = f(x_0) + f'(x_0)h + \dfrac{1}{2} f''(x_0)h + o(h)
\end{equation*}
Il resto in questo caso è espresso dall'\textit{o}-piccolo, ma esiste anche un'
altra formula dove il resto viene espresso in maniera differente:
\thm{
	\textbf{Taylor ordine 2 con resto secondo Lagrange in $\mathbb{R}^1$}: 
	Sia $I \subseteq \mathbb{R}$ e sia $f: I \to \mathbb{R}$ con derivata 
	prima e seconda continue sull'intervallo aperto $I$, vale che:
	\begin{equation*}
        \forall x_0 \in I, x_0 + h \in I, \exists \theta \in ]0,1[: \; f(x_0 + h) = 
		f(x_0) + f'(x_0)h + f''(x_0 + \theta h)\dfrac{h^2}{2}
	\end{equation*}
}
Da notare che in questo caso il resto non si trova nell'\textit{o}-piccolo 
(anche perché è assente), ma bensì nel termine di secondo grado. In particolare nel 
fatto che la matrice Hessiana non viene valutata nel punto esatto $x_0$, ma in 
una sorta di punto medio tra $x_0$ e $h$, cioè $x_0 + \theta h$.
\pf{
	Per dimostrare il teorema facciamo la sostituzione $x_0 + h = x$. Ci 
	riduciamo quindi a voler dimostrare che:
	\begin{equation*}
		\forall x_0,x \in I, \exists \theta \in ]0,1[:\;\; f(x) = f(x_0) 
		+ f'(x_0) (x - x_0) + f''(x_0 + \theta (x - x_0)) \dfrac{(x - 
		x_0)^2}{2}
	\end{equation*}
	Osserviamo che:
	\begin{equation*}
		\exists k \in \mathbb{R}: \; f(x) - f(x_0) - f'(x_0) (x - x_0) 
		- k (x - x_0)^2 = 0
	\end{equation*}
	Questo perché se $(x - x_0) \neq 0$ (caso banale) è una semplice 
	equazione di primo grado in $k$. Riduciamoci quindi a dimostrare che:
	\begin{equation*}
		\exists \theta \in ]0,1[: k = \dfrac{f''(x_0 + \theta 
		(x - x_0))}{2}
	\end{equation*}
	Consideriamo la funzione ausiliaria $g: [x_0, x] \to \mathbb{R}$:
	\begin{equation*}
		g(t) = f(x) - f(t) - f'(t)(x - t) - k(x - t)^2
	\end{equation*}
	Notiamo che grazie a questa costruzione:
	\begin{equation*}
		g(x) = f(x) - f(x) - f'(x)(x - x) - k(x - x)^2 = -f'(x)\cdot 0 
		- k \cdot 0 = 0
	\end{equation*}
	Inoltre:
	\begin{equation*}
		g(x_0) = f(x) - f(x_0) - f'(x_0)(x - x_0) - k(x - x_0)^2 = 0 
	\end{equation*}
	Questo vale proprio per la scelta di $k$ fatta in precedenza. Essendo 
	la funzione derivabile ed essendo nulla agli estremi del dominio 
	possiamo applicare il teorema di Rolle:
	\begin{equation*}
		\exists \theta \in ]0, 1[ : \; g'(x_0 + \theta (x - x_0)) = 0
	\end{equation*}
	Calcoliamo la derivata:
	\begin{equation*}
		g'(t) =  -f'(t) - f''(t)(x - t) - f'(t) \cdot -1 - 2k(x - t) 
		\cdot -1 = [-f''(t) + 2k](x - t)
	\end{equation*}
	Per il teorema di Rolle appena applicato:
	\begin{equation*}
		[-f''(x_0 + \theta (x - x_0)) + 2k](x - (x_0 + \theta (x - 
		x_0))) = 0
	\end{equation*}
	Notiamo che il secondo fattore è diverso da zero in quanto:
	\begin{equation*}
		x - (x_0 + \theta (x - x_0)) = x - x_0 - \theta (x - x_0) = (x 
		- x_0) (\theta - 1)
	\end{equation*}
	Essendo infatti $x \neq x_0$ e $\theta \in ]0, 1[$. Ne consegue che:
	\begin{equation*}
		-f''(x_0 + \theta (x - x_0)) + 2k = 0 \implies k = \dfrac{f''
		(x_0 + \theta (x - x_0))}{2}
	\end{equation*}
	\hfill Qed.
}
Il teorema vale anche in generale :
\thm{
	\textbf{Taylor ordine 2 con resto secondo Lagrange in $\mathbb{R}^n$}: 
	Sia $A \subseteq \mathbb{R}^n$ e sia $f: A \to \mathbb{R}$ con derivate 
	prime e seconde continue, vale che: $\forall x_0 \in A, \forall h \in 
	\mathbb{R}^n$ tale che il segmento $\{x_0 + th: t \in [0, 1]\} 
	\subseteq A$, $\exists \theta \in ]0,1[$ tale che:
	\begin{equation*}
		 f(x_0 + h) = f(x_0) + \langle \nabla f(x_0), h \rangle + 
		 \dfrac{1}{2} \langle \mathbf{H}f(x_0 + \theta h)h, h \rangle
	\end{equation*}
}
\pf{
	Sia $f, x_0$ e $h$ come da ipotesi. Consideriamo ora la funzione 
    ausiliaria $g : [0, 1] \to \mathbb{R}$ definita come segue:
	\begin{equation*}
		g(t) = f(x_0 + th)
	\end{equation*}
	La funzione è derivabile due volte e quindi valgono le formule:
	\begin{equation*}
		g'(t) = \odv{}{t}f(x_0 + th) = \langle \nabla f(x_0 + th), h 
		\rangle = \sum_{j = 1}^n \partial_j f(x_0 + th)h_j
	\end{equation*}
	Si noti che questa derivata è data dal Teorema per le derivate composte 
	(Sezione:  \ref{theorem_derivateComposte}).
	\begin{equation*}
		g''(t) = \odv{}{t} \sum_{j = 1}^n \partial_j f(x_0 + th)h_j = 
		\sum_{j,k = 1}^n \partial_{jk} f(x_0 + th) h_kh_j = \langle 
		\mathbf{H}f(x_0 + th)h, h \rangle 
	\end{equation*}
	Se ora applichiamo la formula di Taylor per il secondo ordine sulla 
	funzione $g$:
	\begin{equation*}
		\exists \theta \in ]0,1[: \; g(x_0 + h) = g(x_0) + g'(x_0)h + 
		g''(x_0 + \theta h)\dfrac{h^2}{2}
	\end{equation*}
	Scegliamo appositamente $x_0 = 0$ e $h = 1$. La formula quindi diventa:
	\begin{equation*}
		g(1) = g(0) + g'(0) + \dfrac{1}{2} g''(\theta)
	\end{equation*}
	Facendo ora le sostituzioni con le formule ottenute in precedenza:
	\begin{equation*}
		 f(x_0 + h) = f(x_0) + \langle \nabla f(x_0), h \rangle + 
		 \dfrac{1}{2} \langle \mathbf{H}f(x_0 + \theta h)h, h \rangle
	\end{equation*}
	\hfill Qed.
}
\textbf{Corollario:} (Formula di Taylor con resto in forma di 
\textit{o}-piccolo (forma di Peano)). Sia $A \subseteq \mathbb{R}^n$ aperto e 
sia $f: A \to \mathbb{R}$ con derivate prime e seconde continue, vale che: 
$\forall x_0 \in A, \exists \delta > 0$ tale che $\forall h \in \mathcal{B}(0, 
\delta)$:
\begin{equation*}
	f(x_0 + h) = f(x_0) + \langle \nabla f(x_0), h \rangle + \dfrac{1}{2} 
	\langle \mathbf{H}f(x_0)h, h \rangle + o(\lVert h \rVert^2)
\end{equation*}

Dimostrazione: La dimostrazione segue dalla formula di Taylor con resto secondo 
Lagrange. Infatti aggiungendo e sottraendo il termine $\frac{1}{2}\langle 
\mathbf{H}f(x_0)h, h \rangle$:
\begin{equation*}
	f(x_0 + h) = f(x_0) + \langle \nabla f(x_0), h \rangle + \dfrac{1}{2} 
	\langle \mathbf{H}f(x_0 + \theta h)h, h \rangle - \frac{1}{2}\langle 
	\mathbf{H}f(x_0)h, h \rangle + \frac{1}{2}\langle \mathbf{H}f(x_0)h, h 
	\rangle
\end{equation*}
Riduciamoci quindi a dimostrare che:
\begin{equation*}
	\dfrac{1}{2} \langle \mathbf{H}f(x_0 + \theta h)h, h \rangle - \frac{1}
	{2}\langle \mathbf{H}f(x_0)h, h \rangle = o(\lVert h \rVert^2)
\end{equation*}
Eliminando $\frac{1}{2}$ in quanto costante e usando la linearità del prodotto 
scalare:
\begin{equation*}
	\langle (\mathbf{H}f(x_0 + \theta h) - \mathbf{H}f(x_0))h, h \rangle = 
	o(\lVert h \rVert^2)
\end{equation*}
Riscrivendo la forma quadratica come sommatoria:
\begin{equation*}
	\sum_{j, k = 1}^n (\partial_{jk} f(x_0 + \theta h) - \partial_{jk} 
	f(x_0))h_jh_k = o(\lVert h \rVert^2)
\end{equation*}
Essendo una sommatoria ci basta dimostare che ogni parte è \textit{o}-piccolo 
della norma al quadrato di $h$. Per farlo prendiamo un termine generico e 
dimostriamo:
\begin{equation*}
	(\partial_{jk} f(x_0 + \theta h) - \partial_{jk} f(x_0))h_jh_k = 
	o(\lVert h \rVert^2)
\end{equation*}
Cioè espandendo la definzione di \textit{o}-piccolo:
\begin{equation*}
	\lim_{h \to \underline{0}} \dfrac{ (\partial_{jk} f(x_0 + \theta h) - 
	\partial_{jk} f(x_0))h_jh_k}{\lVert h \rVert^2} = 0
\end{equation*}
Notiamo che $h_jh_k \leq \lVert h \rVert^2$ in quanto $h_jh_k \leq h_1^2 + 
\cdots + h_j^2 + \cdots + h_k^2 + \cdots + h_n^2$. Infatti ci basta provare 
che $h_jh_k \leq h_j^2 + h_k^2$. Cioè che $h_j^2 + h_k^2 - h_jh_k \geq 0 
\implies 2h_j^2 + 2h_k^2 - 2h_jh_k \geq 0 \implies h_j^2 + h_k^2 + (h_j - 
h_k)^2 \geq 0$. Ovvio quindi in quanto tutti i termini sono di secondo grado e 
quindi positivi. Possiamo quindi dire che:
\begin{align*}
	&\lim_{h \to \underline{0}} \dfrac{ (\partial_{jk} f(x_0 + \theta h) - 
	\partial_{jk} f(x_0))h_jh_k}{\lVert h \rVert^2} \leq \lim_{h \to 
	\underline{0}} \dfrac{ (\partial_{jk} f(x_0 + \theta h) - \partial_{jk} 
	f(x_0))\lVert h \rVert^2}{\lVert h \rVert^2}\\[5pt]
	&\lim_{h \to \underline{0}} (\partial_{jk} f(x_0 + \theta h) - 
	\partial_{jk} f(x_0))
\end{align*}

Essendo la derivata seconda continua:
\begin{equation*}
	\lim_{h \to \underline{0}} (\partial_{jk} f(x_0 + \theta h) - 
	\partial_{jk} f(x_0)) = 0
\end{equation*}
\hfill Qed.

\imp{
	Il \textbf{polinomio di Taylor di grado due} con punto iniziale 
	$\mathbf{x_0}$:
	\begin{equation*}
		T_2(x) = f(x_0) + \langle \nabla f(x_0), (x - x_0) \rangle + 
		\dfrac{1}{2} \langle \mathbf{H}f(x_0) (x - x_0), (x - x_0) 
		\rangle
	\end{equation*}
}

